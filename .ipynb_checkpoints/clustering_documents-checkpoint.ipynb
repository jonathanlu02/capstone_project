{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/saumyaashah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/saumyaashah/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('punkt')\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_json('news_articles_with_text_3_sources.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'id': 'abc-news', 'name': 'ABC News'}</td>\n",
       "      <td>MARIAM FAM, DEEPTI HAJELA and LUIS ANDRES HENA...</td>\n",
       "      <td>Two decades after 9/11, Muslim Americans still...</td>\n",
       "      <td>https://abcnews.go.com/Lifestyle/wireStory/dec...</td>\n",
       "      <td>2021-09-07T07:27:55Z</td>\n",
       "      <td>Muslim Americans who grew up under the shadow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'id': 'abc-news', 'name': 'ABC News'}</td>\n",
       "      <td>TERESA M. WALKER AP Pro Football Writer</td>\n",
       "      <td>Titans' outbreak nears end, other NFL teams de...</td>\n",
       "      <td>https://abcnews.go.com/Sports/wireStory/titans...</td>\n",
       "      <td>2021-09-07T03:31:36Z</td>\n",
       "      <td>The Tennessee Titans COVID-19 outbreak is near...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'id': 'abc-news', 'name': 'ABC News'}</td>\n",
       "      <td>Dr. Priscilla Hanudel</td>\n",
       "      <td>COVID-19 infection after vaccination and what ...</td>\n",
       "      <td>https://abcnews.go.com/Health/covid-19-infecti...</td>\n",
       "      <td>2021-09-07T14:28:39Z</td>\n",
       "      <td>Vaccines work to dramatically reduce the risk ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'id': 'abc-news', 'name': 'ABC News'}</td>\n",
       "      <td>Alisa Wiersema</td>\n",
       "      <td>Texas governor signs GOP-backed 'election inte...</td>\n",
       "      <td>https://abcnews.go.com/Politics/texas-governor...</td>\n",
       "      <td>2021-09-07T17:34:12Z</td>\n",
       "      <td>Three months and two special sessions after Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'id': 'abc-news', 'name': 'ABC News'}</td>\n",
       "      <td>The Associated Press</td>\n",
       "      <td>Spanish hospital baby switch discovered two de...</td>\n",
       "      <td>https://abcnews.go.com/Lifestyle/wireStory/spa...</td>\n",
       "      <td>2021-09-07T17:07:13Z</td>\n",
       "      <td>Health authorities in Spain are blaming human ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   source  \\\n",
       "0  {'id': 'abc-news', 'name': 'ABC News'}   \n",
       "1  {'id': 'abc-news', 'name': 'ABC News'}   \n",
       "2  {'id': 'abc-news', 'name': 'ABC News'}   \n",
       "3  {'id': 'abc-news', 'name': 'ABC News'}   \n",
       "4  {'id': 'abc-news', 'name': 'ABC News'}   \n",
       "\n",
       "                                              author  \\\n",
       "0  MARIAM FAM, DEEPTI HAJELA and LUIS ANDRES HENA...   \n",
       "1            TERESA M. WALKER AP Pro Football Writer   \n",
       "2                              Dr. Priscilla Hanudel   \n",
       "3                                     Alisa Wiersema   \n",
       "4                               The Associated Press   \n",
       "\n",
       "                                               title  \\\n",
       "0  Two decades after 9/11, Muslim Americans still...   \n",
       "1  Titans' outbreak nears end, other NFL teams de...   \n",
       "2  COVID-19 infection after vaccination and what ...   \n",
       "3  Texas governor signs GOP-backed 'election inte...   \n",
       "4  Spanish hospital baby switch discovered two de...   \n",
       "\n",
       "                                                 url           publishedAt  \\\n",
       "0  https://abcnews.go.com/Lifestyle/wireStory/dec...  2021-09-07T07:27:55Z   \n",
       "1  https://abcnews.go.com/Sports/wireStory/titans...  2021-09-07T03:31:36Z   \n",
       "2  https://abcnews.go.com/Health/covid-19-infecti...  2021-09-07T14:28:39Z   \n",
       "3  https://abcnews.go.com/Politics/texas-governor...  2021-09-07T17:34:12Z   \n",
       "4  https://abcnews.go.com/Lifestyle/wireStory/spa...  2021-09-07T17:07:13Z   \n",
       "\n",
       "                                        article_text  \n",
       "0  Muslim Americans who grew up under the shadow ...  \n",
       "1  The Tennessee Titans COVID-19 outbreak is near...  \n",
       "2  Vaccines work to dramatically reduce the risk ...  \n",
       "3  Three months and two special sessions after Te...  \n",
       "4  Health authorities in Spain are blaming human ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, tokenizer, stopwords):\n",
    "    \"\"\"Pre-process text and generate tokens\n",
    "\n",
    "    Args:\n",
    "        text: Text to tokenize.\n",
    "\n",
    "    Returns:\n",
    "        Tokenized text.\n",
    "    \"\"\"\n",
    "    text = str(text).lower()  # Lowercase words\n",
    "    text = re.sub(r\"\\[(.*?)\\]\", \"\", text)  # Remove [+XYZ chars] in content\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # Remove multiple spaces in content\n",
    "    text = re.sub(r\"\\w+…|…\", \"\", text)  # Remove ellipsis (and last word)\n",
    "    text = re.sub(r\"(?<=\\w)-(?=\\w)\", \" \", text)  # Replace dash between words\n",
    "    text = re.sub(\n",
    "        f\"[{re.escape(string.punctuation)}]\", \"\", text\n",
    "    )  # Remove punctuation\n",
    "\n",
    "    tokens = tokenizer(text)  # Get tokens from text\n",
    "    tokens = [t for t in tokens if not t in stopwords]  # Remove stopwords\n",
    "    tokens = [\"\" if t.isdigit() else t for t in tokens]  # Remove digits\n",
    "    tokens = [t for t in tokens if len(t) > 1]  # Remove short tokens\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe: (1500, 6)\n",
      "Pre-processed dataframe: (1494, 2)\n"
     ]
    }
   ],
   "source": [
    "custom_stopwords = set(stopwords.words(\"english\") + [\"news\", \"new\", \"top\"])\n",
    "text_columns = [\"title\", \"author\", \"article_text\"]\n",
    "\n",
    "df = df_raw.copy()\n",
    "df[\"article_text\"] = df[\"article_text\"].fillna(\"\")\n",
    "\n",
    "for col in text_columns:\n",
    "    df[col] = df[col].astype(str)\n",
    "\n",
    "# Create text column based on title, description, and content\n",
    "df[\"text\"] = df[text_columns].apply(lambda x: \" | \".join(x), axis=1)\n",
    "df[\"tokens\"] = df[\"text\"].map(lambda x: clean_text(x, word_tokenize, custom_stopwords))\n",
    "\n",
    "# Remove duplicated after preprocessing\n",
    "_, idx = np.unique(df[\"tokens\"], return_index=True)\n",
    "df = df.iloc[idx, :]\n",
    "\n",
    "# Remove empty values and keep relevant columns\n",
    "df = df.loc[df.tokens.map(lambda x: len(x) > 0), [\"text\", \"tokens\"]]\n",
    "\n",
    "print(f\"Original dataframe: {df_raw.shape}\")\n",
    "print(f\"Pre-processed dataframe: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>More than 1,000km from Sydney, one of NSW's mo...</td>\n",
       "      <td>[1000km, sydney, one, nsws, precious, ecosyste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>12th inmate dies as New York City's jail crisi...</td>\n",
       "      <td>[12th, inmate, dies, york, citys, jail, crisis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>16yo critical after 9m fall from Gold Coast ba...</td>\n",
       "      <td>[16yo, critical, 9m, fall, gold, coast, balcon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>1st trial in college admissions scandal gets u...</td>\n",
       "      <td>[1st, trial, college, admissions, scandal, get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2nd Circuit affirms conviction of former top C...</td>\n",
       "      <td>[2nd, circuit, affirms, conviction, former, cu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "1249  More than 1,000km from Sydney, one of NSW's mo...   \n",
       "731   12th inmate dies as New York City's jail crisi...   \n",
       "492   16yo critical after 9m fall from Gold Coast ba...   \n",
       "325   1st trial in college admissions scandal gets u...   \n",
       "23    2nd Circuit affirms conviction of former top C...   \n",
       "\n",
       "                                                 tokens  \n",
       "1249  [1000km, sydney, one, nsws, precious, ecosyste...  \n",
       "731   [12th, inmate, dies, york, citys, jail, crisis...  \n",
       "492   [16yo, critical, 9m, fall, gold, coast, balcon...  \n",
       "325   [1st, trial, college, admissions, scandal, get...  \n",
       "23    [2nd, circuit, affirms, conviction, former, cu...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_docs = df['tokens'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df['text'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=tokenized_docs, vector_size=100, workers=1, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trump', 0.9893220663070679),\n",
       " ('joe', 0.9862522482872009),\n",
       " ('former', 0.9841845631599426),\n",
       " ('donald', 0.9841769337654114),\n",
       " ('administration', 0.9791196584701538),\n",
       " ('president', 0.9724687933921814),\n",
       " ('press', 0.9509657621383667),\n",
       " ('jen', 0.9441584944725037),\n",
       " ('vice', 0.942875325679779),\n",
       " ('senate', 0.9407942295074463)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"biden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494, 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vectorize(list_of_docs, model):\n",
    "    \"\"\"Generate vectors for list of documents using a Word Embedding\n",
    "\n",
    "    Args:\n",
    "        list_of_docs: List of documents\n",
    "        model: Gensim's Word Embedding\n",
    "\n",
    "    Returns:\n",
    "        List of document vectors\n",
    "    \"\"\"\n",
    "    features = []\n",
    "\n",
    "    for tokens in list_of_docs:\n",
    "        zero_vector = np.zeros(model.vector_size)\n",
    "        vectors = []\n",
    "        for token in tokens:\n",
    "            if token in model.wv:\n",
    "                try:\n",
    "                    vectors.append(model.wv[token])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        if vectors:\n",
    "            vectors = np.asarray(vectors)\n",
    "            avg_vec = vectors.mean(axis=0)\n",
    "            features.append(avg_vec)\n",
    "        else:\n",
    "            features.append(zero_vector)\n",
    "    return features\n",
    "    \n",
    "vectorized_docs = vectorize(tokenized_docs, model=model)\n",
    "len(vectorized_docs), len(vectorized_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mbkmeans_clusters(X, k, mb, print_silhouette_values):\n",
    "    km = MiniBatchKMeans(n_clusters=k, batch_size=mb).fit(X)\n",
    "    print(f\"For n_clusters = {k}\")\n",
    "    print(f\"Silhouette coefficient: {silhouette_score(X, km.labels_):0.2f}\")\n",
    "    print(f\"Inertia:{km.inertia_}\")\n",
    "\n",
    "    if print_silhouette_values:\n",
    "        sample_silhouette_values = silhouette_samples(X, km.labels_)\n",
    "        print(f\"Silhouette values:\")\n",
    "        silhouette_values = []\n",
    "        for i in range(k):\n",
    "            cluster_silhouette_values = sample_silhouette_values[km.labels_ == i]\n",
    "            silhouette_values.append(\n",
    "                (\n",
    "                    i,\n",
    "                    cluster_silhouette_values.shape[0],\n",
    "                    cluster_silhouette_values.mean(),\n",
    "                    cluster_silhouette_values.min(),\n",
    "                    cluster_silhouette_values.max(),\n",
    "                )\n",
    "            )\n",
    "        silhouette_values = sorted(\n",
    "            silhouette_values, key=lambda tup: tup[2], reverse=True\n",
    "        )\n",
    "        for s in silhouette_values:\n",
    "            print(\n",
    "                f\"    Cluster {s[0]}: Size:{s[1]} | Avg:{s[2]:.2f} | Min:{s[3]:.2f} | Max: {s[4]:.2f}\"\n",
    "            )\n",
    "    return km, km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 50\n",
      "Silhouette coefficient: 0.20\n",
      "Inertia:50.06377599928166\n",
      "Silhouette values:\n",
      "    Cluster 23: Size:7 | Avg:0.69 | Min:0.55 | Max: 0.76\n",
      "    Cluster 19: Size:13 | Avg:0.45 | Min:0.13 | Max: 0.63\n",
      "    Cluster 37: Size:19 | Avg:0.43 | Min:0.03 | Max: 0.63\n",
      "    Cluster 28: Size:17 | Avg:0.39 | Min:0.11 | Max: 0.57\n",
      "    Cluster 45: Size:2 | Avg:0.38 | Min:0.30 | Max: 0.46\n",
      "    Cluster 22: Size:25 | Avg:0.37 | Min:0.10 | Max: 0.56\n",
      "    Cluster 4: Size:17 | Avg:0.34 | Min:0.02 | Max: 0.58\n",
      "    Cluster 1: Size:28 | Avg:0.32 | Min:0.05 | Max: 0.55\n",
      "    Cluster 33: Size:19 | Avg:0.32 | Min:-0.03 | Max: 0.50\n",
      "    Cluster 9: Size:53 | Avg:0.28 | Min:0.04 | Max: 0.55\n",
      "    Cluster 29: Size:42 | Avg:0.28 | Min:0.05 | Max: 0.52\n",
      "    Cluster 5: Size:33 | Avg:0.27 | Min:-0.06 | Max: 0.53\n",
      "    Cluster 44: Size:7 | Avg:0.26 | Min:0.12 | Max: 0.43\n",
      "    Cluster 36: Size:6 | Avg:0.26 | Min:0.08 | Max: 0.45\n",
      "    Cluster 13: Size:24 | Avg:0.26 | Min:0.02 | Max: 0.47\n",
      "    Cluster 17: Size:31 | Avg:0.25 | Min:-0.01 | Max: 0.51\n",
      "    Cluster 27: Size:11 | Avg:0.25 | Min:0.03 | Max: 0.40\n",
      "    Cluster 2: Size:58 | Avg:0.25 | Min:-0.05 | Max: 0.49\n",
      "    Cluster 3: Size:36 | Avg:0.24 | Min:-0.00 | Max: 0.45\n",
      "    Cluster 8: Size:6 | Avg:0.22 | Min:-0.07 | Max: 0.39\n",
      "    Cluster 14: Size:23 | Avg:0.22 | Min:-0.03 | Max: 0.41\n",
      "    Cluster 48: Size:83 | Avg:0.22 | Min:-0.02 | Max: 0.46\n",
      "    Cluster 34: Size:43 | Avg:0.22 | Min:-0.01 | Max: 0.46\n",
      "    Cluster 16: Size:7 | Avg:0.22 | Min:0.00 | Max: 0.35\n",
      "    Cluster 25: Size:97 | Avg:0.21 | Min:-0.01 | Max: 0.47\n",
      "    Cluster 20: Size:89 | Avg:0.21 | Min:0.00 | Max: 0.47\n",
      "    Cluster 38: Size:21 | Avg:0.20 | Min:0.04 | Max: 0.38\n",
      "    Cluster 10: Size:30 | Avg:0.20 | Min:0.01 | Max: 0.40\n",
      "    Cluster 35: Size:24 | Avg:0.19 | Min:-0.02 | Max: 0.44\n",
      "    Cluster 46: Size:15 | Avg:0.19 | Min:-0.02 | Max: 0.36\n",
      "    Cluster 21: Size:32 | Avg:0.19 | Min:-0.09 | Max: 0.40\n",
      "    Cluster 24: Size:17 | Avg:0.19 | Min:-0.07 | Max: 0.48\n",
      "    Cluster 39: Size:39 | Avg:0.18 | Min:-0.13 | Max: 0.37\n",
      "    Cluster 18: Size:47 | Avg:0.18 | Min:-0.07 | Max: 0.42\n",
      "    Cluster 0: Size:51 | Avg:0.17 | Min:-0.02 | Max: 0.36\n",
      "    Cluster 26: Size:53 | Avg:0.14 | Min:-0.06 | Max: 0.34\n",
      "    Cluster 11: Size:20 | Avg:0.14 | Min:-0.10 | Max: 0.34\n",
      "    Cluster 31: Size:53 | Avg:0.14 | Min:-0.06 | Max: 0.36\n",
      "    Cluster 42: Size:13 | Avg:0.13 | Min:-0.02 | Max: 0.28\n",
      "    Cluster 32: Size:25 | Avg:0.13 | Min:-0.14 | Max: 0.40\n",
      "    Cluster 43: Size:50 | Avg:0.12 | Min:-0.12 | Max: 0.38\n",
      "    Cluster 49: Size:43 | Avg:0.11 | Min:-0.06 | Max: 0.29\n",
      "    Cluster 7: Size:37 | Avg:0.11 | Min:-0.11 | Max: 0.30\n",
      "    Cluster 15: Size:23 | Avg:0.11 | Min:-0.09 | Max: 0.31\n",
      "    Cluster 6: Size:31 | Avg:0.10 | Min:-0.10 | Max: 0.34\n",
      "    Cluster 41: Size:17 | Avg:0.08 | Min:-0.08 | Max: 0.29\n",
      "    Cluster 12: Size:15 | Avg:0.08 | Min:-0.20 | Max: 0.29\n",
      "    Cluster 47: Size:11 | Avg:-0.02 | Min:-0.14 | Max: 0.13\n",
      "    Cluster 40: Size:5 | Avg:-0.06 | Min:-0.34 | Max: 0.22\n",
      "    Cluster 30: Size:26 | Avg:-0.16 | Min:-0.40 | Max: 0.07\n"
     ]
    }
   ],
   "source": [
    "clustering, cluster_labels = mbkmeans_clusters(\n",
    "\tX=vectorized_docs,\n",
    "    k=50,\n",
    "    mb=500,\n",
    "    print_silhouette_values=True,\n",
    ")\n",
    "df_clusters = pd.DataFrame({\n",
    "    \"text\": docs,\n",
    "    \"tokens\": [\" \".join(text) for text in tokenized_docs],\n",
    "    \"cluster\": cluster_labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most representative terms per cluster (based on centroids):\n",
      "Cluster 0: result conditions showed remains sent appeared denied june research due \n",
      "Cluster 1: moments fun character merchandise music look incredible themed grand musical \n",
      "Cluster 2: russian rep warned hes intelligence called congressional hold governor handling \n",
      "Cluster 3: within company airport october large began gave full flight entry \n",
      "Cluster 4: favorite resorts spa experiences attractions tuned studios entertainment imagineers makers \n",
      "Cluster 5: known personal mission recently business looking group train apple father \n",
      "Cluster 6: students experts education analysis university protection local women investigators hospital \n",
      "Cluster 7: shooting suspect student taken identified taylor chicago charges robinson jail \n",
      "Cluster 8: attorney spokesperson york justice staff documents judge public superintendent officers \n",
      "Cluster 9: violent saw program building oil bears jobs twitter although highly \n",
      "Cluster 10: vaccination risk severe pfizer unvaccinated hospital protection cdc test vaccines \n",
      "Cluster 11: crew different food creating show line always space restaurant rooms \n",
      "Cluster 12: away class heard season little opened site construction five limited \n",
      "Cluster 13: little away limited entire de season history construction site winning \n",
      "Cluster 14: records data medical deaths workers cases mandates mandate fully coronavirus \n",
      "Cluster 15: lawsuit defense filed authorities prosecutors reported attorneys investigation seeking agency \n",
      "Cluster 16: cases school vaccine records public victoria vaccinated data spokesperson attorney \n",
      "Cluster 17: patients vaccines hospitalized severe pfizer vaccination students risk hospital positive \n",
      "Cluster 18: suicide single left initial mother violent far men considered highly \n",
      "Cluster 19: celebrate worlds adventure guests theme blog enchantment contemporary disneys favorite \n",
      "Cluster 20: due result showed significant conditions remain possible research level sent \n",
      "Cluster 21: investigators university comment review anchor confirmed agency county respond saturday \n",
      "Cluster 22: schumer leader sanders gop sen lawmakers budget negotiations plan legislation \n",
      "Cluster 23: return fish launch content gave international company business water complete \n",
      "Cluster 24: officer anchor affiliate released investigation reported medical officers county authorities \n",
      "Cluster 25: allegations results critical issued actions ongoing late defendants claims stop \n",
      "Cluster 26: education investigators university protection experts criminal analysis interest august confirmed \n",
      "Cluster 27: investigators anchor sunday scott review saturday comment university morning agency \n",
      "Cluster 28: records data deaths medical mandate cases mandates workers coronavirus safety \n",
      "Cluster 29: away start project open small enter online de growing war \n",
      "Cluster 30: washington asked agenda senior gop adviser sen policy cheney newsom \n",
      "Cluster 31: conditions research showed sent level result remain due ap remains \n",
      "Cluster 32: pixar fun visit film moments hotel beginning locations incredible merchandise \n",
      "Cluster 33: inspired enjoy epcot stories visiting oct cruise experience celebrating check \n",
      "Cluster 34: independent reports ongoing call concerned results order argued actions concerns \n",
      "Cluster 35: taylor station allegedly incident brown employee korea fbi miami mother \n",
      "Cluster 36: girl illinois milwaukee died son missing shot student boy daughter \n",
      "Cluster 37: characters experience special epcot hotels earidescent inspired cruise stories entertainment \n",
      "Cluster 38: saying rule executive response attorneys governors hes defense riot priority \n",
      "Cluster 39: incident received allegedly related fbi trial employee showed research crime \n",
      "Cluster 40: reporters officials tuesday wednesday mayorkas monday homeland conference thursday capitol \n",
      "Cluster 41: officers records medical data officer investigation reported safety authorities mandate \n",
      "Cluster 42: photo space career pumpkin create gold stage chef follow add \n",
      "Cluster 43: mission group left community fight father germany waiting scene hit \n",
      "Cluster 44: boy girl two hawaii son daughter woman ago gabby killed \n",
      "Cluster 45: inspired oct epcot enjoy earidescent experience stories celebrating cruise visiting \n",
      "Cluster 46: officer officers investigation released reported authorities medical judge county city \n",
      "Cluster 47: justice judge documents officers investigation attorney officer city defense staff \n",
      "Cluster 48: saw left violent fight suicide bears followed building single program \n",
      "Cluster 49: investigators county university reported confirmed review prosecutors authorities agency comment \n"
     ]
    }
   ],
   "source": [
    "print(\"Most representative terms per cluster (based on centroids):\")\n",
    "for i in range(50):\n",
    "    tokens_per_cluster = \"\"\n",
    "    most_representative = model.wv.most_similar(positive=[clustering.cluster_centers_[i]], topn=10)\n",
    "    for t in most_representative:\n",
    "        tokens_per_cluster += f\"{t[0]} \"\n",
    "    print(f\"Cluster {i}: {tokens_per_cluster}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c50298a6cd8637dc5be37cd1f58589b776fed233ef5d6cd701fc376c52bb812"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
